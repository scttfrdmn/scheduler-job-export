# HPC Multi-Scheduler Data Export & Analysis Toolkit

**Production-ready tools for exporting, anonymizing, and analyzing job data from all major HPC schedulers.**

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Schedulers: 5](https://img.shields.io/badge/Schedulers-5-blue.svg)](#supported-schedulers)
[![Documentation: 40k+ words](https://img.shields.io/badge/Docs-40k%2B%20words-green.svg)](#documentation)

---

## ğŸ¯ Purpose

This toolkit enables comprehensive behavioral analysis of HPC cluster usage by:

1. **Exporting** job history and cluster configuration from any major HPC scheduler
2. **Anonymizing** user data while preserving usage patterns
3. **Analyzing** submission behavior, utilization, and cloud bursting opportunities

**Primary Use Case:** Test the hypothesis that users avoid submitting jobs during periods of high cluster congestion ("submission abandonment").

---

## âœ¨ Key Features

### ğŸ”„ Universal Scheduler Support

Export data from **all major HPC schedulers** with standardized output:

| Scheduler | Job Export | Cluster Config | Status |
|-----------|------------|----------------|--------|
| **SLURM** | âœ… | âœ… | Production |
| **LSF** (IBM Spectrum) | âœ… | âœ… | Production |
| **PBS/Torque/PBS Pro** | âœ… | âœ… | Production |
| **UGE/SGE/OGE** | âœ… | âœ… | Production |
| **HTCondor** | âœ… | âœ… | Production |

All exporters produce **identical CSV format** for seamless analysis.

### ğŸ”’ Privacy-Preserving Anonymization

- Deterministic mapping: `jsmith` â†’ `user_0001`
- Preserves behavioral patterns
- Auto-detects user/group columns
- Secure mapping file management

### ğŸ“Š Comprehensive Analysis

- **Submission abandonment** - Do users avoid submitting during congestion?
- **True utilization** - Compare usage vs. actual capacity
- **Cloud bursting ROI** - Calculate hybrid cloud savings
- **Concurrent load** - Utilization time series
- **Multi-site comparison** - Cross-scheduler behavioral studies

### ğŸ“š Extensive Documentation

**40,000+ words** of documentation including:
- Scheduler-specific export guides
- Troubleshooting for every scheduler
- Privacy and anonymization workflows
- Institutional approval guidance
- Complete analysis tutorials

---

## ğŸš€ Quick Start

### For SLURM

```bash
# 1. Export cluster configuration
./export_slurm_cluster_config.sh

# 2. Export job history
./export_with_users.sh

# 3. Anonymize
./anonymize_cluster_data.sh \
  slurm_jobs_with_users.csv \
  slurm_anonymized.csv \
  mapping.txt

# 4. Analyze
python3 analyze_concurrent_load.py
python3 analyze_submission_abandonment_events.py
```

### For Other Schedulers

**LSF:**
```bash
./export_lsf_comprehensive.sh 2024/01/01 2024/12/31
```

**PBS:**
```bash
sudo ./export_pbs_comprehensive.sh 20240101 20241231
```

**UGE/SGE:**
```bash
./export_uge_comprehensive.sh 01/01/2024 12/31/2024
```

See [scheduler-specific guides](#documentation) for complete instructions.

---

## ğŸ“‹ Requirements

### System Requirements
- Bash 4.0+
- Python 3.6+
- Pandas (for analysis scripts)

### Scheduler Access
- Read access to scheduler accounting data
- Admin privileges may be required (PBS, LSF with `-a` flag)
- Scheduler-specific commands available:
  - SLURM: `sacct`, `sinfo`
  - LSF: `bhist`, `bhosts`
  - PBS: `pbsnodes`, accounting logs
  - UGE: `qacct`, `qhost`
  - HTCondor: `condor_history`, `condor_status`

---

## ğŸ“ Repository Structure

```
cluster-job-analysis/
â”œâ”€â”€ README.md                           # This file
â”‚
â”œâ”€â”€ Export Scripts/
â”‚   â”œâ”€â”€ export_slurm_cluster_config.sh  # SLURM cluster inventory
â”‚   â”œâ”€â”€ export_lsf_comprehensive.sh     # LSF complete export
â”‚   â”œâ”€â”€ export_lsf_cluster_config.sh    # LSF cluster inventory
â”‚   â”œâ”€â”€ export_pbs_comprehensive.sh     # PBS complete export
â”‚   â”œâ”€â”€ export_pbs_cluster_config.sh    # PBS cluster inventory
â”‚   â”œâ”€â”€ export_uge_comprehensive.sh     # UGE complete export
â”‚   â”œâ”€â”€ export_uge_cluster_config.sh    # UGE cluster inventory
â”‚   â”œâ”€â”€ export_htcondor_data.sh         # HTCondor export
â”‚   â””â”€â”€ export_cluster_configs_all.sh   # Auto-detect any scheduler
â”‚
â”œâ”€â”€ Utilities/
â”‚   â”œâ”€â”€ anonymize_cluster_data.sh       # Privacy-preserving anonymization
â”‚   â”œâ”€â”€ standardize_cluster_config.py   # Normalize config formats
â”‚   â””â”€â”€ analyze_cluster_config.py       # Cluster capacity analysis
â”‚
â”œâ”€â”€ Analysis Scripts/
â”‚   â”œâ”€â”€ analyze_concurrent_load.py      # Utilization over time
â”‚   â”œâ”€â”€ analyze_submission_abandonment_events.py  # Test hypothesis
â”‚   â”œâ”€â”€ analyze_jobs.py                 # Basic statistics
â”‚   â”œâ”€â”€ analyze_utilization.py          # Utilization metrics
â”‚   â”œâ”€â”€ analyze_packing.py              # Node packing efficiency
â”‚   â”œâ”€â”€ analyze_slurm_cloud_bursting.py # Cloud ROI
â”‚   â””â”€â”€ analyze_full_aws_migration.py   # Full migration analysis
â”‚
â”œâ”€â”€ Documentation/
â”‚   â”œâ”€â”€ COMPLETE_TOOLKIT_SUMMARY.md     # Master overview
â”‚   â”œâ”€â”€ LSF_EXPORT_GUIDE.md             # LSF detailed guide
â”‚   â”œâ”€â”€ PBS_EXPORT_GUIDE.md             # PBS detailed guide
â”‚   â”œâ”€â”€ UGE_EXPORT_GUIDE.md             # UGE/SGE detailed guide
â”‚   â”œâ”€â”€ MULTI_SCHEDULER_EXPORT_README.md # All schedulers reference
â”‚   â”œâ”€â”€ TWO_PART_EXPORT_GUIDE.md        # Why config + jobs matters
â”‚   â”œâ”€â”€ ANONYMIZATION_README.md         # Privacy workflow
â”‚   â”œâ”€â”€ INSTITUTIONAL_APPROVAL_CASE.md  # Getting approval
â”‚   â”œâ”€â”€ OSCAR_Cluster_Analysis.md       # Example analysis
â”‚   â””â”€â”€ CLOUD_COMPARISON_ANALYSIS.md    # Cloud economics
â”‚
â””â”€â”€ Testing/
    â”œâ”€â”€ test_anonymization.sh           # Validate anonymization
    â”œâ”€â”€ generate_mock_user_group_data.py # Test data generation
    â””â”€â”€ generate_sample_data_with_users.sh # Sample data
```

---

## ğŸ“ Use Cases

### 1. Submission Abandonment Study

**Hypothesis:** Users avoid submitting jobs when the queue is long.

**Process:**
1. Export job history from 10-20 HPC sites
2. Anonymize all user data
3. Analyze correlation between queue depth and submission rate
4. Compare across different utilization levels

**Expected Results:**
- Overprovisioned clusters: weak effect (r â‰ˆ -0.1)
- Normally loaded: moderate effect (r â‰ˆ -0.2 to -0.3)
- Underprovisioned (4-7x): strong effect (r â‰ˆ -0.4 to -0.5)

### 2. True Utilization Calculation

**Problem:** Job data only shows nodes that ran jobs, not total capacity.

**Solution:**
1. Export cluster configuration (all nodes)
2. Export job history (what was used)
3. Calculate: `utilization = peak_usage / total_capacity`

**Example:**
```
Cluster capacity: 13,920 CPUs (from config)
Peak concurrent:  12,500 CPUs (from jobs)
True utilization: 89.8%
```

### 3. Cloud Bursting ROI

**Analysis:**
1. Identify peak usage periods
2. Calculate overflow beyond on-prem capacity
3. Price AWS spot instances for overflow
4. Compare cost vs. expanding on-prem

**Example Finding:**
- OSCAR: $7.4M savings over 3 years with cloud bursting vs. 2x cluster expansion

### 4. Cross-Scheduler Comparison

**Question:** Do users behave differently on different schedulers?

**Process:**
1. Export from multiple sites with different schedulers
2. Standardize all formats
3. Compare submission patterns, utilization, abandonment behavior
4. Control for utilization level and workload type

### 5. Multi-Site Behavioral Studies

**Goal:** Understand HPC usage patterns across the ecosystem

**Requirements:**
- 10-20 sites
- Mixed schedulers (SLURM, LSF, PBS, UGE)
- Mixed utilization (overprovisioned to heavily contended)
- Mixed scales (100 to 10,000+ nodes)

---

## ğŸ“– Documentation

### Getting Started
- **[COMPLETE_TOOLKIT_SUMMARY.md](COMPLETE_TOOLKIT_SUMMARY.md)** - Complete overview of all tools
- **[MULTI_SCHEDULER_EXPORT_README.md](MULTI_SCHEDULER_EXPORT_README.md)** - Quick reference for all schedulers
- **[TWO_PART_EXPORT_GUIDE.md](TWO_PART_EXPORT_GUIDE.md)** - Why you need config + job data

### Scheduler-Specific Guides
- **[LSF_EXPORT_GUIDE.md](LSF_EXPORT_GUIDE.md)** - Complete IBM Spectrum LSF guide
- **[PBS_EXPORT_GUIDE.md](PBS_EXPORT_GUIDE.md)** - Complete PBS/Torque guide
- **[UGE_EXPORT_GUIDE.md](UGE_EXPORT_GUIDE.md)** - Complete UGE/SGE guide

### Process Guides
- **[ANONYMIZATION_README.md](ANONYMIZATION_README.md)** - Privacy and anonymization
- **[INSTITUTIONAL_APPROVAL_CASE.md](INSTITUTIONAL_APPROVAL_CASE.md)** - Getting institutional approval

### Analysis Examples
- **[OSCAR_Cluster_Analysis.md](OSCAR_Cluster_Analysis.md)** - Brown University OSCAR analysis
- **[CLOUD_COMPARISON_ANALYSIS.md](CLOUD_COMPARISON_ANALYSIS.md)** - Cloud economics comparison
- **[USER_GROUP_ANALYSIS_OPPORTUNITIES.md](USER_GROUP_ANALYSIS_OPPORTUNITIES.md)** - Behavioral analysis ideas

---

## ğŸ”¬ Example Results

### OSCAR Cluster (Brown University)

**Dataset:** 6,991,376 jobs over ~1 year

**Key Findings:**
- Median queue time: 1.93 minutes (overprovisioned!)
- Peak concurrent: 14,645 CPUs
- Mean concurrent: 7,883 CPUs
- **Submission abandonment detected:** r = -0.09 (weak but present)

**Conclusion:** Even on an overprovisioned cluster where queue checking provides minimal benefit, users still exhibit abandonment behavior. On heavily contended clusters, this effect would be much stronger.

**Business Impact:** Cloud bursting could save $7.4M over 3 years vs. expanding on-prem capacity by 2x.

---

## ğŸ” Privacy & Security

### Anonymization

The toolkit provides **deterministic, privacy-preserving anonymization**:

**What gets anonymized:**
- âœ… Usernames â†’ `user_0001`, `user_0002`, ...
- âœ… Groups â†’ `group_A`, `group_B`, ...
- âœ… Accounts â†’ `account_X`, `account_Y`, ...

**What stays the same:**
- âœ… All timestamps (submit, start, end)
- âœ… All resource requests (CPUs, memory)
- âœ… All usage patterns
- âœ… Job dependencies and sequences

**Mapping file security:**
```bash
# Mapping file links anonymous â†” real identities
chmod 600 mapping_secure.txt
sudo mv mapping_secure.txt /root/secure/

# Never share mapping file
# Only share anonymized CSV
```

### Data Handling Best Practices

1. **Export** on secure system (scheduler head node)
2. **Anonymize** immediately after export
3. **Secure** mapping file (root-only access)
4. **Delete** original export with real usernames
5. **Encrypt** for transfer (GPG or SSH)
6. **Share** only anonymized data

See [ANONYMIZATION_README.md](ANONYMIZATION_README.md) for complete workflow.

---

## ğŸŒ Supported Schedulers

### SLURM (Simple Linux Utility for Resource Management)

**Common in:** Universities, national labs, cloud HPC
**Commands:** `sacct`, `sinfo`
**Date format:** `YYYY-MM-DD`
**Output:** Native CSV
**Guide:** Built-in documentation + [MULTI_SCHEDULER_EXPORT_README.md](MULTI_SCHEDULER_EXPORT_README.md)

### LSF (IBM Spectrum LSF)

**Common in:** National labs, commercial HPC, financial services
**Commands:** `bhist`, `bhosts`, `lshosts`
**Date format:** `YYYY/MM/DD`
**Output:** Text paragraphs â†’ parsed to CSV
**Guide:** [LSF_EXPORT_GUIDE.md](LSF_EXPORT_GUIDE.md)

### PBS/Torque/PBS Pro

**Common in:** Universities, DOD, research institutions
**Commands:** `pbsnodes`, accounting logs
**Date format:** `YYYYMMDD`
**Output:** Semicolon-delimited logs â†’ parsed to CSV
**Guide:** [PBS_EXPORT_GUIDE.md](PBS_EXPORT_GUIDE.md)
**Note:** Requires root/admin access for accounting logs

### UGE/SGE/OGE (Univa/Sun/Open Grid Engine)

**Common in:** Legacy installations, academic clusters
**Commands:** `qacct`, `qhost`
**Date format:** `MM/DD/YYYY` âš ï¸ **Unique!**
**Output:** Text with separators â†’ parsed to CSV
**Guide:** [UGE_EXPORT_GUIDE.md](UGE_EXPORT_GUIDE.md)

### HTCondor

**Common in:** High-throughput computing, OSG
**Commands:** `condor_history`, `condor_status`
**Date format:** Days ago (integer)
**Output:** Tab-separated â†’ converted to CSV
**Guide:** [MULTI_SCHEDULER_EXPORT_README.md](MULTI_SCHEDULER_EXPORT_README.md)

---

## ğŸ’¡ Tips & Best Practices

### Exporting Data

1. **Start small** - Test with 1 month of data first
2. **Check permissions** - Some schedulers require admin access
3. **Verify output** - Always check CSV before anonymization
4. **Export both parts** - Cluster config + job history
5. **Document metadata** - Record scheduler version, date range, site info

### Anonymization

1. **Anonymize immediately** - Don't leave raw data sitting around
2. **Secure mapping file** - Root-only access, encrypted backups
3. **Verify anonymization** - Check no real usernames remain
4. **Delete originals** - Remove raw export after anonymization
5. **Test first** - Use test script on sample data

### Analysis

1. **Validate data** - Check for reasonable values, complete timestamps
2. **Start with basics** - Run `analyze_jobs.py` first
3. **Understand capacity** - Always analyze cluster config
4. **Compare thoughtfully** - Control for utilization, workload, scale
5. **Document assumptions** - Note data quality issues, filters applied

---

## ğŸ¤ Contributing

This toolkit is designed for HPC research and operations. Contributions welcome:

- **Bug reports** - Scheduler-specific parsing issues
- **New schedulers** - Add support for additional schedulers
- **Analysis scripts** - New analytical approaches
- **Documentation** - Improved guides, examples
- **Test cases** - Validation on different environments

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ™ Acknowledgments

**Data Source:**
- Brown University OSCAR cluster data used for initial validation

**Schedulers:**
- SLURM by SchedMD
- IBM Spectrum LSF
- Altair PBS Pro / OpenPBS / Torque
- Univa Grid Engine / Sun Grid Engine / Open Grid Engine
- HTCondor by University of Wisconsin-Madison

---

## ğŸ“ Support

### Documentation
Start with [COMPLETE_TOOLKIT_SUMMARY.md](COMPLETE_TOOLKIT_SUMMARY.md) for comprehensive overview.

### Scheduler-Specific Issues
See scheduler guides:
- [LSF_EXPORT_GUIDE.md](LSF_EXPORT_GUIDE.md)
- [PBS_EXPORT_GUIDE.md](PBS_EXPORT_GUIDE.md)
- [UGE_EXPORT_GUIDE.md](UGE_EXPORT_GUIDE.md)

### Common Issues

**"Command not found"**
- Source scheduler environment file
- Check scheduler installation path

**"Permission denied"**
- Some schedulers require admin access
- See scheduler guide for fallback options

**"No data exported"**
- Verify date format for your scheduler
- Check accounting is enabled
- Confirm date range has data

**Troubleshooting checklists** in each scheduler guide.

---

## ğŸ¯ Project Goals

1. **Enable behavioral research** - Understand how users interact with HPC schedulers
2. **Test submission abandonment** - Quantify avoidance behavior during congestion
3. **Improve resource efficiency** - Data-driven provisioning decisions
4. **Support cloud adoption** - ROI analysis for hybrid cloud
5. **Cross-site comparison** - Learn from ecosystem-wide patterns

---

## ğŸ“Š Project Status

**Current:** Production ready, all 5 major schedulers supported

**Next Steps:**
- Multi-site data collection (target: 10-20 sites)
- Cross-scheduler behavioral comparison
- Publication of findings
- Cloud bursting ROI calculator web tool

---

## ğŸš€ Getting Started Checklist

- [ ] Choose your scheduler from [supported list](#supported-schedulers)
- [ ] Read scheduler-specific [export guide](#documentation)
- [ ] Set up scheduler environment (PATH, environment variables)
- [ ] Test export on small date range (1 month)
- [ ] Verify CSV output looks correct
- [ ] Export full dataset (6-12 months recommended)
- [ ] Export cluster configuration
- [ ] Anonymize data using `anonymize_cluster_data.sh`
- [ ] Secure mapping file (root-only access)
- [ ] Run `analyze_jobs.py` for basic validation
- [ ] Run `analyze_concurrent_load.py` for utilization
- [ ] Run `analyze_submission_abandonment_events.py` to test hypothesis
- [ ] Review [analysis documentation](#documentation)
- [ ] Share findings (anonymized data only!)

---

**Ready to analyze your HPC cluster?** Start with your scheduler's [export guide](#documentation)! ğŸ“ˆ
